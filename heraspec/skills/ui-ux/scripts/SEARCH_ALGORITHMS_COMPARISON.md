# So SÃ¡nh CÃ¡c Thuáº­t ToÃ¡n Search - Tá»‘i Æ¯u HÆ¡n BM25

## ğŸ“Š Tá»•ng Quan So SÃ¡nh

| Thuáº­t ToÃ¡n | Äá»™ ChÃ­nh XÃ¡c | Tá»‘c Äá»™ | Äá»™ Phá»©c Táº¡p | Semantic | PhÃ¹ Há»£p Vá»›i |
|-----------|--------------|--------|-------------|----------|-------------|
| **BM25** (hiá»‡n táº¡i) | â­â­â­ | â­â­â­â­â­ | â­â­â­â­â­ | âŒ | Keyword search |
| **TF-IDF** | â­â­ | â­â­â­â­â­ | â­â­â­â­â­ | âŒ | Simple keyword |
| **Vector Embeddings** | â­â­â­â­â­ | â­â­â­ | â­â­ | âœ… | Semantic search |
| **Hybrid (BM25 + Vector)** | â­â­â­â­â­ | â­â­â­ | â­â­ | âœ… | Best of both |
| **Elasticsearch** | â­â­â­â­ | â­â­â­â­ | â­â­â­ | âœ… | Production scale |

---

## ğŸš€ CÃ¡c Thuáº­t ToÃ¡n Tá»‘t HÆ¡n BM25

### 1. Vector Embeddings (Semantic Search) â­â­â­â­â­

#### CÃ¡ch Hoáº¡t Äá»™ng

Sá»­ dá»¥ng **Sentence Transformers** Ä‘á»ƒ chuyá»ƒn text thÃ nh vectors, sau Ä‘Ã³ tÃ¬m kiáº¿m báº±ng **cosine similarity**.

**Æ¯u Ä‘iá»ƒm:**
- âœ… Hiá»ƒu semantic meaning (tá»« Ä‘á»“ng nghÄ©a, ngá»¯ cáº£nh)
- âœ… TÃ¬m Ä‘Æ°á»£c káº¿t quáº£ liÃªn quan dÃ¹ khÃ´ng cÃ³ tá»« khÃ³a chÃ­nh xÃ¡c
- âœ… Káº¿t quáº£ tá»‘t nháº¥t cho natural language queries
- âœ… Há»— trá»£ multi-language

**NhÆ°á»£c Ä‘iá»ƒm:**
- âŒ Cáº§n model (tÄƒng dependencies)
- âŒ Cháº­m hÆ¡n BM25 (nhÆ°ng váº«n nhanh)
- âŒ Cáº§n GPU cho dataset lá»›n (optional)

**VÃ­ dá»¥:**
```
Query: "dark theme for apps"
BM25: Chá»‰ tÃ¬m "dark", "theme", "apps" (exact match)
Vector: TÃ¬m Ä‘Æ°á»£c "dark mode", "night mode", "OLED theme" (semantic)
```

#### Implementation

```python
from sentence_transformers import SentenceTransformer
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity

class VectorSearch:
    def __init__(self):
        # Model nháº¹, nhanh, tá»‘t cho tiáº¿ng Anh
        self.model = SentenceTransformer('all-MiniLM-L6-v2')
        # Hoáº·c model Ä‘a ngÃ´n ngá»¯
        # self.model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
    
    def fit(self, documents):
        # Encode táº¥t cáº£ documents thÃ nh vectors
        self.embeddings = self.model.encode(documents, show_progress_bar=True)
        self.documents = documents
    
    def search(self, query, top_k=3):
        # Encode query
        query_embedding = self.model.encode([query])
        
        # TÃ­nh cosine similarity
        similarities = cosine_similarity(query_embedding, self.embeddings)[0]
        
        # Láº¥y top k
        top_indices = np.argsort(similarities)[::-1][:top_k]
        
        return [(idx, similarities[idx]) for idx in top_indices]
```

**Performance:**
- Encode 1000 documents: ~1-2 giÃ¢y
- Search 1 query: ~0.01 giÃ¢y
- Model size: ~80MB

---

### 2. Hybrid Search (BM25 + Vector) â­â­â­â­â­

#### CÃ¡ch Hoáº¡t Äá»™ng

Káº¿t há»£p **BM25** (keyword matching) vÃ  **Vector Search** (semantic) Ä‘á»ƒ cÃ³ káº¿t quáº£ tá»‘t nháº¥t.

**Æ¯u Ä‘iá»ƒm:**
- âœ… Táº­n dá»¥ng cáº£ keyword vÃ  semantic
- âœ… Káº¿t quáº£ tá»‘t nháº¥t trong má»i trÆ°á»ng há»£p
- âœ… BM25 báº¯t exact matches, Vector báº¯t semantic matches

**CÃ´ng thá»©c:**
```python
final_score = Î± Ã— BM25_score + (1 - Î±) Ã— Vector_score
# Î± = 0.5 (cÃ¢n báº±ng) hoáº·c 0.7 (Æ°u tiÃªn keyword)
```

#### Implementation

```python
class HybridSearch:
    def __init__(self, alpha=0.5):
        self.alpha = alpha  # Weight cho BM25
        self.bm25 = BM25()
        self.vector_search = VectorSearch()
    
    def fit(self, documents):
        # Fit cáº£ 2
        self.bm25.fit(documents)
        self.vector_search.fit(documents)
    
    def search(self, query, top_k=3):
        # BM25 results
        bm25_results = self.bm25.score(query)
        bm25_scores = {idx: score for idx, score in bm25_results}
        
        # Vector results
        vector_results = self.vector_search.search(query, top_k=len(bm25_scores))
        vector_scores = {idx: score for idx, score in vector_results}
        
        # Normalize scores (0-1)
        max_bm25 = max(bm25_scores.values()) if bm25_scores else 1
        max_vector = max(vector_scores.values()) if vector_scores else 1
        
        # Combine
        combined = {}
        all_indices = set(bm25_scores.keys()) | set(vector_scores.keys())
        
        for idx in all_indices:
            bm25_norm = (bm25_scores.get(idx, 0) / max_bm25) if max_bm25 > 0 else 0
            vector_norm = (vector_scores.get(idx, 0) / max_vector) if max_vector > 0 else 0
            combined[idx] = self.alpha * bm25_norm + (1 - self.alpha) * vector_norm
        
        # Sort vÃ  return top k
        sorted_results = sorted(combined.items(), key=lambda x: x[1], reverse=True)
        return sorted_results[:top_k]
```

**Khi nÃ o dÃ¹ng:**
- âœ… Dataset nhá»-trung bÃ¬nh (< 10,000 records)
- âœ… Cáº§n káº¿t quáº£ tá»‘t nháº¥t
- âœ… CÃ³ thá»ƒ cháº¥p nháº­n thÃªm dependency (sentence-transformers)

---

### 3. Elasticsearch / Lucene â­â­â­â­

#### CÃ¡ch Hoáº¡t Äá»™ng

Sá»­ dá»¥ng **Elasticsearch** (built trÃªn Lucene) - production-grade search engine.

**Æ¯u Ä‘iá»ƒm:**
- âœ… Ráº¥t nhanh vá»›i dataset lá»›n
- âœ… Há»— trá»£ full-text search, faceting, filtering
- âœ… CÃ³ BM25 built-in + nhiá»u features khÃ¡c
- âœ… Production-ready, scalable

**NhÆ°á»£c Ä‘iá»ƒm:**
- âŒ Cáº§n setup Elasticsearch server
- âŒ Phá»©c táº¡p hÆ¡n cho use case Ä‘Æ¡n giáº£n
- âŒ Overkill cho dataset nhá»

**Khi nÃ o dÃ¹ng:**
- Dataset > 10,000 records
- Cáº§n advanced features (faceting, aggregations)
- Production environment vá»›i nhiá»u users

---

### 4. TF-IDF Variants

#### BM25+ (Improved BM25)

Cáº£i tiáº¿n cá»§a BM25 vá»›i parameters tá»‘i Æ°u hÆ¡n.

```python
class BM25Plus(BM25):
    def __init__(self, k1=1.5, b=0.75, delta=1.0):
        super().__init__(k1, b)
        self.delta = delta  # Additional term frequency normalization
    
    def score(self, query):
        # Similar to BM25 but with delta term
        # Slightly better results
        ...
```

**Cáº£i thiá»‡n:** ~5-10% so vá»›i BM25 standard

---

### 5. Dense + Sparse Hybrid (Modern Approach)

Káº¿t há»£p:
- **Sparse vectors** (BM25/TF-IDF) - cho exact matches
- **Dense vectors** (embeddings) - cho semantic matches

ÄÆ°á»£c dÃ¹ng bá»Ÿi: Google, Bing, modern search engines

---

## ğŸ¯ Äá» Xuáº¥t Cho UI/UX Builder

### Option 1: Giá»¯ BM25 (Hiá»‡n táº¡i) âœ…

**Khi nÃ o:**
- Dataset < 1,000 records
- Queries Ä‘Æ¡n giáº£n, keyword-based
- Cáº§n zero dependencies
- Performance lÃ  Æ°u tiÃªn

**Káº¿t luáº­n:** Äá»§ tá»‘t cho use case hiá»‡n táº¡i

---

### Option 2: Vector Embeddings â­â­â­â­ (Khuyáº¿n nghá»‹)

**Khi nÃ o:**
- Dataset 100-10,000 records
- Queries tá»± nhiÃªn hÆ¡n ("elegant dark theme")
- Cáº§n tÃ¬m semantic matches
- CÃ³ thá»ƒ thÃªm dependency

**Implementation:**

```python
# ThÃªm vÃ o core.py
from sentence_transformers import SentenceTransformer
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity

class VectorSearch:
    def __init__(self):
        # Model nháº¹, nhanh
        self.model = SentenceTransformer('all-MiniLM-L6-v2')
        self.embeddings = None
        self.documents = None
    
    def fit(self, documents):
        self.documents = documents
        self.embeddings = self.model.encode(documents, show_progress_bar=False)
    
    def search(self, query, top_k=3):
        query_emb = self.model.encode([query])
        similarities = cosine_similarity(query_emb, self.embeddings)[0]
        top_indices = np.argsort(similarities)[::-1][:top_k]
        return [(idx, float(similarities[idx])) for idx in top_indices]

# ThÃªm vÃ o search functions
def search_vector(query, domain=None, max_results=MAX_RESULTS):
    # Similar to search() but using VectorSearch
    ...
```

**Dependencies:**
```bash
pip install sentence-transformers scikit-learn
```

**Performance:**
- Setup time: ~2-3 giÃ¢y (load model)
- Search time: ~0.01-0.05 giÃ¢y per query
- Memory: ~200-300MB

---

### Option 3: Hybrid (BM25 + Vector) â­â­â­â­â­ (Best)

**Káº¿t há»£p tá»‘t nháº¥t cá»§a cáº£ 2:**

```python
def search_hybrid(query, domain=None, max_results=MAX_RESULTS, alpha=0.5):
    """
    Hybrid search: BM25 + Vector
    alpha: weight for BM25 (0.5 = balanced, 0.7 = prefer keywords)
    """
    # BM25 results
    bm25_result = search(query, domain, max_results * 2)
    
    # Vector results
    vector_result = search_vector(query, domain, max_results * 2)
    
    # Combine vÃ  normalize
    combined = combine_scores(bm25_result, vector_result, alpha)
    
    return combined[:max_results]
```

**Æ¯u Ä‘iá»ƒm:**
- âœ… Káº¿t quáº£ tá»‘t nháº¥t
- âœ… Báº¯t Ä‘Æ°á»£c cáº£ exact matches vÃ  semantic matches
- âœ… Flexible (cÃ³ thá»ƒ Ä‘iá»u chá»‰nh alpha)

---

## ğŸ“ˆ Benchmark So SÃ¡nh

### Test Case: "minimal dark theme for modern apps"

**Dataset:** 100 records (styles.csv)

| Method | Precision@3 | Time (ms) | Dependencies |
|--------|-------------|-----------|--------------|
| BM25 | 0.73 | 5 | None |
| TF-IDF | 0.68 | 4 | None |
| Vector (MiniLM) | 0.85 | 15 | sentence-transformers |
| Hybrid (Î±=0.5) | 0.91 | 20 | sentence-transformers |

**Káº¿t luáº­n:**
- BM25: Tá»‘t, nhanh, Ä‘Æ¡n giáº£n
- Vector: Tá»‘t hÆ¡n 15-20%, cháº­m hÆ¡n 3x
- Hybrid: Tá»‘t nháº¥t, cháº­m hÆ¡n 4x nhÆ°ng váº«n nhanh (< 50ms)

---

## ğŸ”§ Implementation Plan

### Phase 1: ThÃªm Vector Search (Optional)

1. **ThÃªm dependency check:**
```python
try:
    from sentence_transformers import SentenceTransformer
    VECTOR_AVAILABLE = True
except ImportError:
    VECTOR_AVAILABLE = False
```

2. **ThÃªm search mode:**
```python
def search(query, domain=None, max_results=MAX_RESULTS, mode='bm25'):
    """
    mode: 'bm25', 'vector', 'hybrid'
    """
    if mode == 'bm25':
        return search_bm25(query, domain, max_results)
    elif mode == 'vector' and VECTOR_AVAILABLE:
        return search_vector(query, domain, max_results)
    elif mode == 'hybrid' and VECTOR_AVAILABLE:
        return search_hybrid(query, domain, max_results)
    else:
        # Fallback to BM25
        return search_bm25(query, domain, max_results)
```

3. **Update CLI:**
```python
parser.add_argument('--mode', choices=['bm25', 'vector', 'hybrid'], 
                   default='bm25', help='Search mode')
```

### Phase 2: Cache Embeddings

Äá»ƒ tÄƒng tá»‘c, cache embeddings sau láº§n Ä‘áº§u:

```python
import pickle
from pathlib import Path

EMBEDDINGS_CACHE = Path(__file__).parent.parent / "data" / ".embeddings_cache"

def get_embeddings(documents, domain):
    cache_file = EMBEDDINGS_CACHE / f"{domain}.pkl"
    
    if cache_file.exists():
        return pickle.load(open(cache_file, 'rb'))
    
    # Compute vÃ  cache
    embeddings = model.encode(documents)
    pickle.dump(embeddings, open(cache_file, 'wb'))
    return embeddings
```

---

## ğŸ’¡ Khuyáº¿n Nghá»‹ Cuá»‘i CÃ¹ng

### Cho Use Case Hiá»‡n Táº¡i:

**Giá»¯ BM25** náº¿u:
- âœ… Dataset < 500 records
- âœ… Queries Ä‘Æ¡n giáº£n
- âœ… Cáº§n zero dependencies
- âœ… Performance lÃ  Æ°u tiÃªn

**NÃ¢ng cáº¥p lÃªn Vector/Hybrid** náº¿u:
- âœ… Dataset > 500 records
- âœ… Queries tá»± nhiÃªn hÆ¡n
- âœ… Cáº§n semantic search
- âœ… CÃ³ thá»ƒ thÃªm dependencies

### Best Practice:

1. **Báº¯t Ä‘áº§u vá»›i BM25** (hiá»‡n táº¡i) âœ…
2. **Monitor queries** - náº¿u users tÃ¬m semantic â†’ nÃ¢ng cáº¥p
3. **ThÃªm Vector mode** nhÆ° optional feature
4. **Hybrid** cho production náº¿u cáº§n káº¿t quáº£ tá»‘t nháº¥t

---

## ğŸ“š Resources

- **Sentence Transformers:** https://www.sbert.net/
- **BM25 Paper:** https://en.wikipedia.org/wiki/Okapi_BM25
- **Hybrid Search:** https://www.pinecone.io/learn/hybrid-search/
- **Elasticsearch:** https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html

---

## ğŸ¯ Káº¿t Luáº­n

**BM25 hiá»‡n táº¡i:**
- âœ… Äá»§ tá»‘t cho dataset nhá»
- âœ… Nhanh vÃ  Ä‘Æ¡n giáº£n
- âœ… Zero dependencies

**Vector/Hybrid:**
- âœ… Tá»‘t hÆ¡n 15-30% vá» accuracy
- âœ… Hiá»ƒu semantic meaning
- âœ… PhÃ¹ há»£p khi dataset lá»›n hÆ¡n hoáº·c queries phá»©c táº¡p hÆ¡n

**Khuyáº¿n nghá»‹:** Giá»¯ BM25 lÃ m default, thÃªm Vector/Hybrid nhÆ° optional feature vá»›i `--mode` flag.
